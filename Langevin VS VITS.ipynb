{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b5e4c05b",
   "metadata": {},
   "source": [
    "**Comparaision VITS/Langevin**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6444869",
   "metadata": {},
   "source": [
    "Data : \n",
    "\n",
    "Return \n",
    "- X, of dimention, n_samples, n_features\n",
    "- Y of dimention n_targets  * n_samples\n",
    "- theta star is true_weights\n",
    "\n",
    "\n",
    "\n",
    "A fiare varier pour notre problème : \n",
    "\n",
    "- 1) Imporn_features with n_informative features pour l'exploration à montrer\n",
    "- 2) effective_rank : (int)  The approximate number of singular vectors required to explain most of the input data by linear combinations. \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "bias =0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2942918b",
   "metadata": {},
   "source": [
    "A faire varier : n_informative pour le coté exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "167a8e14",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets._samples_generator import check_array, check_random_state, make_low_rank_matrix\n",
    "import numpy as np\n",
    "from sklearn.utils import shuffle as util_shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "1b986f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def regression_model(\n",
    "    n_samples=100,\n",
    "    n_features=100,\n",
    "    n_informative=10,\n",
    "    n_targets=1,\n",
    "    bias=0.0,\n",
    "    effective_rank=None,\n",
    "    tail_strength=0.5,\n",
    "    noise=1,\n",
    "    shuffle=True,\n",
    "    coef=True,\n",
    "    random_state=None,\n",
    "):\n",
    "    \n",
    "    n_informative = min(n_features, n_informative)\n",
    "    generator = check_random_state(random_state)\n",
    "\n",
    "    if effective_rank is None:\n",
    "        # Randomly generate a well conditioned input set\n",
    "        X = generator.standard_normal(size=(n_samples, n_features))\n",
    "    else:\n",
    "        # Randomly generate a low rank, fat tail input set\n",
    "        X = make_low_rank_matrix(\n",
    "            n_samples=n_samples,\n",
    "            n_features=n_features,\n",
    "            effective_rank=effective_rank,\n",
    "            tail_strength=tail_strength,\n",
    "            random_state=generator,\n",
    "        )\n",
    "\n",
    "    ground_truth = np.zeros((n_features, n_targets))\n",
    "    ground_truth[:n_informative, :] = 100 * generator.uniform(\n",
    "        size=(n_informative, n_targets)\n",
    "    )\n",
    "\n",
    "    y = np.dot(X, ground_truth) + bias\n",
    "\n",
    "    # Add noise\n",
    "    if noise > 0.0:\n",
    "        y += generator.normal(scale=noise, size=y.shape)\n",
    "\n",
    "    # Randomly permute samples and features\n",
    "    if shuffle:\n",
    "        X, y = util_shuffle(X, y, random_state=generator)\n",
    "\n",
    "        indices = np.arange(n_features)\n",
    "        generator.shuffle(indices)\n",
    "        X[:, :] = X[:, indices]\n",
    "        ground_truth = ground_truth[indices]\n",
    "\n",
    "    y = np.squeeze(y)\n",
    "\n",
    "    if coef:\n",
    "        return X, y, np.squeeze(ground_truth)\n",
    "    else:\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3b5a3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, true_weights = regression_model(n_samples=200, n_features=20, n_informative=20, n_targets=1, \n",
    " bias=0.0, effective_rank=None, \n",
    " tail_strength=0.5, noise=0.0, \n",
    " shuffle=True, coef=True, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ebcc47ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200, 20), (200,))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape, y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "28b3fd35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([10.34039475, 72.65012421, 87.33781205,  2.28149344, 54.96317257,\n",
       "       59.20795128, 16.82041862, 28.29000988, 28.29327397, 76.29703411,\n",
       "       12.05209099, 18.1921814 , 87.96194328, 41.57946972, 44.02657875,\n",
       "       99.53411171, 38.77696597, 32.78147825, 48.94694433, 33.74727223])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be547fe",
   "metadata": {},
   "source": [
    "**Use only somes informative features for exmploration between Langevin and VITS**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b0bedb8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, true_weights = regression_model(n_samples=200, n_features=20, n_informative=10, n_targets=1, \n",
    " bias=0.0, effective_rank=None, \n",
    " tail_strength=0.5, noise=0.0, \n",
    " shuffle=True, coef=True, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "59880108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([59.34531915,  0.        ,  0.        ,  0.        , 62.60412179,\n",
       "        0.        , 68.41506501, 49.74881603, 49.19828199,  0.        ,\n",
       "       27.61325967,  0.        , 25.02298735,  0.        ,  0.        ,\n",
       "        0.        , 86.116001  , 84.25914542, 33.76544999,  0.        ])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc73b6b",
   "metadata": {},
   "source": [
    "**Use ill conditionned matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f7d7a30c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y, true_weights = regression_model(n_samples=200, n_features=20, n_informative=20, n_targets=1, \n",
    " bias=0.0, effective_rank=3, \n",
    " tail_strength=0.5, noise=0.0, \n",
    " shuffle=True, coef=True, random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "a763599c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([82.63741387, 71.38216631,  2.74751575, 57.17781434,  1.15806037,\n",
       "        2.78369081, 78.33314617, 85.94703388,  2.60762353, 82.27645594,\n",
       "       60.86559265, 47.29645928, 68.26453904, 95.44293411,  3.57438985,\n",
       "       24.11400692, 50.51530983, 15.06318527, 73.19534062, 51.13005124])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc4a9f19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e379251",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LMC():\n",
    "    \n",
    "    def __init__(self,dimention):\n",
    "        \n",
    "        self.dimention=dimention\n",
    "        self.lbd=1\n",
    "        self.eta=1\n",
    "        \n",
    "    def loglik(theta, y , x):\n",
    "        V=self.lbd*np.eye(self.dimension) + x*x.T\n",
    "        b=\n",
    "        return (self.eta/2)*(theta.T*V*theta -2teheta.T*b + np.sum(y**2))\n",
    "    \n",
    "    def gradient(self,y,x):\n",
    "        V=self.lbd*np.eye(self.dimension) + x*x.T\n",
    "        b=\n",
    "        return eta*(V*theta-b)\n",
    "        \n",
    "    def hessian(self,x):\n",
    "        return self.eta*(self.lbd*np.eye(self.dimension) + x*x.T)\n",
    "        \n",
    "    def sample(self,T):\n",
    "        \n",
    "        eps = np.random.normal( shape=(self.dimension, 1))\n",
    "        theta = (mean.T + T * eps).squeeze()\n",
    "        return  theta     \n",
    "\n",
    "    def update_mean(self, mean, gradient, h,T):\n",
    "        return mean - h * gradient + T*noise\n",
    "    \n",
    "    def run(x,y,max_iter=10000):\n",
    "        \n",
    "        # initilialisation mean\n",
    "        mean_0=np.zeros(dimention)\n",
    "        dists=[]\n",
    "           \n",
    "        for t in range(max_iter):\n",
    "            \n",
    "            h=1/(t+1)\n",
    "            # sample\n",
    "            theta=sample(mean,y,x)\n",
    "            # compute grad and hessian\n",
    "            grad,hess=gradient(theta,y,x),hessian(x)\n",
    "        \n",
    "            # Update mean and cov\n",
    "            mean=updade_mean(mean,grad,h)\n",
    "            cov,cov_inv=update_cov(cov,cov_inv,hess,h)\n",
    "            \n",
    "            # compute the distance\n",
    "            dists.append(np.norm(self.true_param-mean))\n",
    "            \n",
    "        return mean, cov ,dists\n",
    "        \n",
    "\n",
    "class VI_gaussian(true_param)\n",
    "\n",
    "    def __init__(self,dimention,approx=False):\n",
    "        \n",
    "        self.dimention=dimention\n",
    "        self.lbd=1\n",
    "        self.eta=1\n",
    "        self.approx=approx\n",
    "        self.true_param=true_param\n",
    "        \n",
    "    \n",
    "    def loglik(theta, y ,x):\n",
    "        V=self.lbd*np.eye(self.dimension) + x*x.T\n",
    "        b=\n",
    "        return (self.eta/2)*(theta.T*V*theta -2teheta.T*b + np.sum(y**2))\n",
    "    \n",
    "    def gradient(self,y,x):\n",
    "        V=self.lbd*np.eye(self.dimension) + x*x.T\n",
    "        b=\n",
    "        return eta*(V*theta-b)\n",
    "        \n",
    "    def hessian(self,x):\n",
    "        return self.eta*(self.lbd*np.eye(self.dimension) + x*x.T)\n",
    "    \n",
    "    \n",
    "    def update_mean(self, mean, gradient, h):\n",
    "        return mean - h * gradient\n",
    "    \n",
    "    def update_cov(self, cov_semi, cov_semi_inv, hessian, h):\n",
    "        cov_semi = (np.eye(self.dimension) - h * hessian) @ cov_semi + h * cov_semi_inv.T\n",
    "        \n",
    "        if self.approx:\n",
    "            cov_semi_inv = cov_semi_inv @ (np.eye(self.dimension) - h * (np.matmul(cov_semi_inv.T , cov_semi_inv) - hessian))\n",
    "        else:\n",
    "            cov_semi_inv = np.linalg.inv(cov_semi)\n",
    "        return cov_semi, cov_semi_inv\n",
    "    \n",
    "    def sample(self, mean, cov_semi):\n",
    "        \n",
    "        eps = np.random.normal( shape=(self.dimension, 1))\n",
    "        theta = (mean.T + cov_semi @ eps).squeeze()\n",
    "        return  theta\n",
    "    \n",
    "    def compute_cond_number(self, mean, cov_semi,label,features):\n",
    "        features, labels, mean, cov_semi, _ = utils_vector\n",
    "        theta = self.sample( mean, cov_semi)\n",
    "        regularization_hessian = 2 * self.lbd * jnp.eye(self.dimension)\n",
    "        data_hessian = np.sum(jax.vmap(self.hessian_function, in_axes=(None, 0, 0))(theta, features, labels), axis=0)\n",
    "        hessian = self.eta *  (regularization_hessian + data_hessian)\n",
    "        return np.linalg.cond(hessian)\n",
    "    \n",
    "    def run(x,y,max_iter=10000):\n",
    "        \n",
    "        # initilialisation, comment déjà pour la cov ?\n",
    "        mean_0=np.zeros(dimention)\n",
    "        cov=self.eta* np.eye(dimention)\n",
    "        dists=[]\n",
    "        cov_inv=(1/self.eta)* np.eye(dimention)\n",
    "        \n",
    "        for t in range(max_iter):\n",
    "            h=1/(t+1)\n",
    "            # sample\n",
    "            theta=sample(mean,cov)\n",
    "            # compute grad and hessian\n",
    "            grad,hess=gradient(theta,y,x),hessian(x)\n",
    "            \n",
    "            # Update mean and cov\n",
    "            mean=updade_mean(mean,grad,h)\n",
    "            cov,cov_inv=update_cov(cov,cov_inv,hess,h)\n",
    "            \n",
    "            # compute the distance\n",
    "            dists.append(np.norm(self.true_param-mean))\n",
    "            \n",
    "        return mean, cov ,dists\n",
    "    \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a7d1db",
   "metadata": {},
   "source": [
    "**Algorrithms** : Langevin : VITS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "707ef5c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
